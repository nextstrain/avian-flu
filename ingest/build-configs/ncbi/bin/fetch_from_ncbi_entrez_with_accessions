#!/usr/bin/env python3
"""
Fetch metadata from NCBI Entrez for the provided file of GenBank accessions.
"""
import argparse
from typing import Iterator, List
from Bio import SeqIO, Entrez, SeqRecord
from augur.io.metadata import write_records_to_tsv

# To use the efetch API, the docs indicate only around 10,000 records should be fetched per request
# https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EFetch
# However, in my testing with HepB, the max records returned was 9,999
#   - Jover, 16 August 2023
BATCH_SIZE = 9999
Entrez.email = "hello@nextstrain.org"


def parse_args():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--genbank-accessions", required=True,
        help="File of GenBank accessions to fetch from Entrez, with one accession per line.")
    parser.add_argument("--source-fields", nargs="+",
        default=["strain", "serotype", "segment"],
        help="Qualifier fields to parse from the source feature of GenBank records")
    parser.add_argument("--id-column-name", default="accession_version",
        help="Column name to use the GenBank record id field.")
    parser.add_argument("--output", required=True,
        help="TSV output file. Accepts '-' to output TSV to stdout.")
    return parser.parse_args()


def read_accessions(accessions_file: str) -> List[str]:
    """
    Reads each line from the provided *accessions_file* and
    returns it them as a single comma-delimited string.

    Expects the first line of the file to be a header and skips it.
    """
    accessions = []
    with open(accessions_file) as file:
        # Skip header line
        next(file)
        for line in file:
            accessions.append(line.rstrip())

    return accessions


def fetch_from_efetch(accessions: List[str]) -> Iterator[Iterator[SeqRecord.SeqRecord]]:
    """
    Fetches the GenBank records for the provided *accessions* from
    Entrez EFetch in batches of `BATCH_SIZE` and yields an iterator of
    individual SeqRecords.
    """
    for i in range(0, len(accessions), BATCH_SIZE):
        batched_accessions = accessions[i:i + BATCH_SIZE]
        handle = Entrez.efetch(
            db='nucleotide',
            id=batched_accessions,
            rettype="gb",
            retmode="text",
        )
        yield SeqIO.parse(handle, "genbank")


def parse_genbank_records(record_batches: Iterator[Iterator[SeqRecord.SeqRecord]],
                          id_field_name: str,
                          source_fields: List[str]) -> Iterator[dict]:
    """
    Parse the provided GenBank *record_batches* to pull out the
    requested *source_fields* from the 'source' feature's qualifiers.

    Yields the parsed records as dict with the GenBank accession (versioned)
    and the requested *source_fields*.
    """
    for batch in record_batches:
        for record in batch:
            source_features = [
                feature for feature in record.features
                if feature.type == 'source'
            ]

            assert len(source_features) == 1, \
                "GenBank records should have one 'source' feature"

            source_qualifiers = source_features[0].qualifiers
            requested_record = {}
            requested_record[id_field_name] = record.id
            requested_record.update({
                # Qualifier fields are returned as lists even though they only have one value
                field: source_qualifiers.get(field, [""])[0]
                for field in source_fields
            })

            yield requested_record


if __name__ == '__main__':
    args = parse_args()

    accessions = read_accessions(args.genbank_accessions)
    fetched_records = fetch_from_efetch(accessions)
    parsed_records = parse_genbank_records(fetched_records,
                                           args.id_column_name,
                                           args.source_fields)
    write_records_to_tsv(parsed_records, args.output)
