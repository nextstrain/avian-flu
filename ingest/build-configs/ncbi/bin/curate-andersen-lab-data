#!/usr/bin/env python3
"""
Curate the metadata that originated from Andersen Lab's avian-influenza repo
<https://github.com/andersen-lab/avian-influenza>.

Parses NDJSON record from stdin and outputs new record to stdout.
"""
import copy
import json
import re
from datetime import datetime
from enum import Enum
from sys import stdin, stdout, stderr
from augur.curate.parse_genbank_location import parse_location


NEXTSTRAIN_RECORD = {
    'strain': '?',
    'virus': 'avian_flu',
    'isolate_id': '?',
    'date': '?',
    'region': '?',
    'country': '?',
    'division': '?',
    'location': '?',
    'host': '?',
    'domestic_status': '?',
    'subtype': 'h5n1',
    'originating_lab': '?',
    'submitting_lab': '?',
    'authors': '?',
    'PMID': '?',
    'gisaid_clade': '?',
    'h5_clade': '?',
    'genbank_accession': '?',
    'sra_accessions': '?',
}


def create_new_record(anderson_record: dict) -> dict:
    """
    Create a new NEXTSTRAIN_RECORD with additional data from the provided
    `andersen_record`.
    """
    new_record = copy.deepcopy(NEXTSTRAIN_RECORD)
    new_record['isolate_id'] = anderson_record['Run']
    new_record['sra_accessions'] = anderson_record['Run']
    new_record['region'] = anderson_record['geo_loc_name_country_continent']
    new_record['country'] = anderson_record['geo_loc_name_country']
    # Parse the geolocation as the GenBank format `country:division,location`
    new_record = parse_location(new_record, 'country')
    # Try to fill `US State` if division and location were not parsed
    if new_record['division'] == '':
        new_record['division'] = anderson_record.get('US State', '')
    if new_record['location'] == '':
        new_record['location'] = anderson_record.get('US State', '')
    new_record['host'] = anderson_record['Host']
    new_record['date_released'] = anderson_record['ReleaseDate']

    new_record['date'] = use_date_when_available(anderson_record)
    center_name = parse_center_name(anderson_record['Center Name'])
    new_record['originating_lab'] = center_name
    new_record['submitting_lab'] = center_name

    new_record['strain'] = construct_strain_name(new_record, anderson_record['isolate'])
    return new_record


def use_date_when_available(andersen_record: dict) -> str:
    """
    Give the old date field `Date` precedence since they are more specific.

    If using the new date field `Collection_Date`, then verify that it's a
    valid date.
    """
    old_date_field = andersen_record.get("Date", "")
    old_date_uncertain = "NA" in old_date_field or "?" in old_date_field

    if old_date_field and not old_date_uncertain:
        return old_date_field

    new_date = andersen_record["Collection_Date"]
    if new_date.lower() == "missing":
        new_date = "XXXX-XX-XX"

    # Certain dates are date ranges, e.g. "2022-04-22/2022-04-24"
    # Only keep the first date for our metadata
    date_range_pattern = r"([\d]{4}-[\d]{2}-[\d]{2})\/[\d]{4}-[\d]{2}-[\d]{2}"
    matches = re.match(date_range_pattern, new_date)
    if matches:
        new_date = matches.group(1)

    try:
        parse_date(new_date)
    except ValueError as err:
        print(f"WARNING: {err}", file=stderr)
        new_date = "XXXX-XX-XX"

    return new_date


def parse_center_name(center_name: str) -> str:
    if center_name == 'USDA-NVSL':
        return center_name.replace('-', ' ')

    return center_name


def construct_strain_name(record: dict, sample_id: str) -> str:
    """
    Check if the *sample_id* is follows a strain name pattern, otherwise
    construct a strain name for the *sample_id* using metadata from the
    *record* to include host, country, and year.

    Removes all spaces in the constructed strain name because they are not
    allowed in the downstream phylogenetic workflow. Also replaces invalid
    characters with `_` to match iqtree¹ so augur tree will not modify strain
    names and cause a mismatch between the tree and the alignment FASTA.²

    ¹ <https://github.com/iqtree/iqtree2/blob/74da454bbd98d6ecb8cb955975a50de59785fbde/utils/tools.cpp#L607>
    ² <https://github.com/nextstrain/avian-flu/issues/113>
    """
    # A/<host>/<location>/<sample_id>/<year>
    strain_pattern = r"(A\/.+\/.+\/.+\/[\d]{4})"
    matches = re.search(strain_pattern, sample_id)
    if matches:
        strain = matches.group(1)
    else:
        host = record['host']
        country = record['country']
        year = str(parse_date(record['date']).year)
        strain = f"A/{host}/{country}/{sample_id}/{year}".replace(" ", "")
    return re.sub(r'[^\w\_\-\.\|\/]', '_', strain)


def parse_date(date_string: str) -> datetime:
    """
    Parse the provided `date_string` as a datetime object.
    """
    date_formats = ['%Y-%m-%d', '%Y', 'XXXX-XX-XX']
    for date_format in date_formats:
        try:
            parsed_date = datetime.strptime(date_string, date_format)
            return parsed_date
        except ValueError:
            continue

    raise ValueError(f"Could not parse date from date string {date_string!r}")


if __name__ == '__main__':

    for record in stdin:
        anderson_record = json.loads(record)
        new_record = create_new_record(anderson_record)
        json.dump(new_record, stdout, allow_nan=False, indent=None, separators=',:')
        print()
